{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# homework6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Yiming Yan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USCID: 9932750243"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set. Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(o_data,train_per=0.7):\n",
    "    data=o_data.copy()\n",
    "    columns=data.columns\n",
    "    training_data=pd.DataFrame(columns=columns)\n",
    "    test_data=pd.DataFrame(columns=columns)\n",
    "    length=len(data.values)\n",
    "    l=round(length*train_per)\n",
    "    ran_num=range(length)\n",
    "    i=0\n",
    "    while i<1:\n",
    "        k=random.choice(ran_num)\n",
    "        index=list(training_data.index)\n",
    "        train_length=len(training_data.values)\n",
    "        if train_length==l:\n",
    "            break\n",
    "        else:\n",
    "          if k in index:\n",
    "             continue\n",
    "          else:\n",
    "            training_data=training_data.append(data.loc[k])\n",
    "            data.drop([k],inplace=True)\n",
    "    test_data=data\n",
    "    training_data.index=range(len(training_data)) \n",
    "    test_data.index=range(len(test_data))\n",
    "    return training_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_set=pd.DataFrame(pd.read_csv('G:/EE559/hw/hw6/Frogs_MFCCs.csv'))\n",
    "training_set,test_set=split_data(origin_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Research exact match and hamming score/ loss methods for evaluating multilabel classi\f",
    "cation and use them in evaluating the classifiers in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score/ Exact match metric: This function calculates subset accuracy meaning the predicted set of labels should exactly match with the true set of labels.Exact match is the most strict metric, indicating the percentage of samples that have all their labels classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming loss is the fraction of the wrong labels to the total number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(y_true,y_predict):\n",
    "    length,width=y_true.shape\n",
    "    count=0\n",
    "    for true,predict in zip(y_true,y_predict):\n",
    "        true=list(true)\n",
    "        predict=list(predict)\n",
    "        if true==predict:\n",
    "            count+=1\n",
    "    fraction=count/length\n",
    "    return fraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both normalized and raw attributes and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrate_data(data):\n",
    "    features=np.array(data.drop(['Family', 'Genus', 'Species', 'RecordID'], axis=1))\n",
    "    label1=np.array(data['Family'])\n",
    "    label2=np.array(data['Genus'])\n",
    "    label3=np.array(data['Species'])\n",
    "    return features,label1,label2,label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel width and Parameter C\n",
    "sigma=[i/10 for i in range(1,21,1)]\n",
    "gamma=[1/(2*sig*sig) for sig in sigma]\n",
    "param_grid={'kernel':['rbf'],'C':[0.01,0.1,1,10,100],'gamma':gamma}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.99999999999999, 12.499999999999998, 5.555555555555555, 3.1249999999999996, 2.0, 1.3888888888888888, 1.0204081632653064, 0.7812499999999999, 0.6172839506172839, 0.5, 0.4132231404958677, 0.3472222222222222, 0.29585798816568043, 0.2551020408163266, 0.2222222222222222, 0.19531249999999997, 0.17301038062283738, 0.15432098765432098, 0.13850415512465375, 0.125]\n"
     ]
    }
   ],
   "source": [
    "print(param_grid['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,training_family,training_genus,training_species=extrate_data(training_set)\n",
    "test_data,test_family,test_genus,test_species=extrate_data(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1 = SVC()\n",
    "svc2 = SVC()\n",
    "svc3 = SVC()\n",
    "family_svc = GridSearchCV(svc1,param_grid,cv = 10,refit=True, n_jobs=-1)\n",
    "genus_svc = GridSearchCV(svc2,param_grid,cv = 10,refit=True,n_jobs=-1)\n",
    "species_svc = GridSearchCV(svc3,param_grid,cv = 10,refit=True,n_jobs=-1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_model=family_svc.fit(training_data,training_family)\n",
    "family_pre = family_model.predict(test_data)\n",
    "wFamily = family_model.best_params_\n",
    "hammingloss1=hamming_loss(test_family,family_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_model=genus_svc.fit(training_data,training_genus)\n",
    "genus_pre = genus_model.predict(test_data)\n",
    "wGenus = genus_model.best_params_\n",
    "hammingloss2=hamming_loss(test_genus,genus_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_model=species_svc.fit(training_data,training_species)\n",
    "species_pre =species_model.predict(test_data)\n",
    "wSpecies = species_model.best_params_\n",
    "\n",
    "label_pre = np.array([family_pre, genus_pre, species_pre]).T\n",
    "label_true= np.array([test_family, test_genus,test_species]).T\n",
    "\n",
    "hammingloss3=hamming_loss(test_species,species_pre)\n",
    "hammingloss=(hammingloss1+hammingloss2+hammingloss3)/3\n",
    "\n",
    "exactmatch=exact_match(label_true,label_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " penalty and width for Family:  10  The gamma is 3.1249999999999996 The sigma is 0.4\n",
      "penalty and width for Genus:  100  The gamma is 1.3888888888888888 The sigma is 0.6\n",
      "penalty and width for Species:  10  The gamma is 2.0 The sigma is 0.5\n",
      "exact match 0.9911996294580825\n",
      "hamming loss 0.0057125212289640265\n"
     ]
    }
   ],
   "source": [
    "print(\" penalty and width for Family: \",wFamily['C'],\" The gamma is\",wFamily['gamma'],\"The sigma is\",math.sqrt(1/(2*wFamily['gamma'])))\n",
    "print(\"penalty and width for Genus: \",wGenus['C'],\" The gamma is\",wGenus['gamma'],\"The sigma is\",math.sqrt(1/(2*wGenus['gamma'])))\n",
    "print(\"penalty and width for Species: \",wSpecies['C'],\" The gamma is\",wSpecies['gamma'],\"The sigma is\",math.sqrt(1/(2*wSpecies['gamma'])))\n",
    "print(\"exact match\", exactmatch)\n",
    "print(\"hamming loss\",hammingloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. Repeat 1(b)ii with L1-penalized SVMs. Remember to normalize the attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the description \"Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an mel-frequency cepstrum (MFC). Due to each syllable has different length, every row (i) was normalized acording to MFCCs_i/(max(abs(MFCCs_i))).\" , the whole data has been normalized.\n",
    "So, I don't need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.001,0.01,0.1,1,10,100,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc1 = LinearSVC(penalty='l1', dual=False)\n",
    "lsvc2 = LinearSVC(penalty='l1', dual=False)\n",
    "lsvc3 = LinearSVC(penalty='l1', dual=False)\n",
    "family_svcl=GridSearchCV(lsvc1,params,cv = 10,refit=True,n_jobs=-1)\n",
    "genus_svcl= GridSearchCV(lsvc2,params,cv = 10,refit=True,n_jobs=-1)\n",
    "species_svcl= GridSearchCV(lsvc3,params,cv = 10,refit=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_modell = family_svcl.fit(training_data,training_family)\n",
    "family_prel = family_modell.predict(test_data)\n",
    "wFamilyl = family_modell.best_params_ \n",
    "hamminglossl1=hamming_loss(test_family,family_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_modell=genus_svcl.fit(training_data,training_genus)\n",
    "genus_prel = genus_modell.predict(test_data)\n",
    "wGenusl=genus_modell.best_params_\n",
    "hamminglossl2=hamming_loss(test_genus,genus_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_modell = species_svcl.fit(training_data,training_species)\n",
    "species_prel =species_modell.predict(test_data)\n",
    "wSpeciesl = species_modell.best_params_\n",
    "\n",
    "label_prel = np.array([family_prel, genus_prel, species_prel]).T\n",
    "label_true= np.array([test_family, test_genus,test_species]).T\n",
    "\n",
    "hamminglossl3=hamming_loss(test_species,species_prel)\n",
    "hamminglossl=(hamminglossl1+hamminglossl2+hamminglossl3)/3\n",
    "\n",
    "exactmatch=exact_match(label_true,label_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " penalty and width for Family:  100\n",
      "penalty and width for Genus:  100\n",
      "penalty and width for Species:  100\n",
      "exact match 0.9212598425196851\n",
      "hamming loss 0.04616334722865525\n"
     ]
    }
   ],
   "source": [
    "print(\" penalty and width for Family: \",wFamilyl['C'])\n",
    "print(\"penalty and width for Genus: \",wGenusl['C'])\n",
    "print(\"penalty and width for Species: \",wSpeciesl['C'])\n",
    "print(\"exact match\", exactmatch)\n",
    "print(\"hamming loss\",hamminglossl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.001,0.01, 0.1,1,10,100,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE()\n",
    "family_data_res,family_label_res = sm.fit_sample(training_data, training_family)\n",
    "genus_data_res,genus_label_res = sm.fit_sample(training_data, training_genus)\n",
    "species_data_res,species_label_res = sm.fit_sample(training_data, training_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc1 = LinearSVC(penalty='l1', dual=False)\n",
    "lsvc2 = LinearSVC(penalty='l1', dual=False)\n",
    "lsvc3 = LinearSVC(penalty='l1', dual=False)\n",
    "family_svcl=GridSearchCV(lsvc1,params,cv = 10,refit=True,n_jobs=-1)\n",
    "genus_svcl= GridSearchCV(lsvc2,params,cv = 10,refit=True,n_jobs=-1)\n",
    "species_svcl= GridSearchCV(lsvc3,params,cv = 10,refit=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_modell = family_svcl.fit(family_data_res,family_label_res)\n",
    "family_prel = family_modell.predict(test_data)\n",
    "wFamilyl = family_modell.best_params_ \n",
    "hamminglossl1=hamming_loss(test_family,family_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_modell=genus_svcl.fit(genus_data_res,genus_label_res)\n",
    "genus_prel = genus_modell.predict(test_data)\n",
    "wGenusl=genus_modell.best_params_\n",
    "hamminglossl2=hamming_loss(test_genus,genus_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_modell = species_svcl.fit(species_data_res,species_label_res)\n",
    "species_prel =species_modell.predict(test_data)\n",
    "wSpeciesl = species_modell.best_params_\n",
    "\n",
    "label_prel = np.array([family_prel, genus_prel, species_prel]).T\n",
    "label_true= np.array([test_family, test_genus,test_species]).T\n",
    "\n",
    "hamminglossl3=hamming_loss(test_species,species_prel)\n",
    "hamminglossl=(hamminglossl1+hamminglossl2+hamminglossl3)/3\n",
    "\n",
    "exactmatch=exact_match(label_true,label_prel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " penalty and width for Family:  100\n",
      "penalty and width for Genus:  1000\n",
      "penalty and width for Species:  100\n",
      "exact match 0.8679944418712366\n",
      "hamming loss 0.06824146981627296\n"
     ]
    }
   ],
   "source": [
    "print(\" penalty and width for Family: \",wFamilyl['C'])\n",
    "print(\"penalty and width for Genus: \",wGenusl['C'])\n",
    "print(\"penalty and width for Species: \",wSpeciesl['C'])\n",
    "print(\"exact match\", exactmatch)\n",
    "print(\"hamming loss\",hamminglossl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
